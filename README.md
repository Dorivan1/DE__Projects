# Data Engineering Projects Repository

## Overview

Welcome to my Data Engineering Projects repository! This repository is a collection of projects I've worked on to demonstrate my abilities, gain new skills, and build robust data engineering solutions. Each project focuses on different aspects of data engineering, from building ETL pipelines to automating workflows and performing data analysis using various BI tools. These projects are for demonstration purposes and each file represents 
a seperate project.

## Purpose

I started working on these projects with the primary goal of improving my data engineering skills. Initially, I did not plan to add them to a GitHub repository, which led to some projects being less well-documented and some files being lost, especially in the early stages. Despite this, I've gained a wealth of experience and knowledge.

## Skills and Technologies

Throughout these projects, I've gained proficiency in a wide range of tools and technologies, including but not limited to:

- **Apache Airflow**: For orchestrating complex workflows.
- **Apache Spark & PySpark**: For large-scale data processing and analysis.
- **Apache Kafka**: For real-time data streaming.
- **AWS Services**: Including S3, Glue, Redshift, and Lambda for various cloud-based data engineering tasks.
- **BI Tools**: For data visualization and business intelligence.
- **SQL**: For database querying and manipulation.
- **Python**: For scripting, data manipulation, and automation.
- **Pandas**: For data analysis and transformation.
- **Requests**: For interacting with APIs.
- **CSV & JSON**: For data storage and exchange.
- **ETL**: For extracting, transforming, and loading data.
- **Jupyter Notebook**: For interactive data analysis and documentation.